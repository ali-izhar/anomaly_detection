# Dataset Configuration

# Data loading settings
data:
    base_dir: "datasets"          # Base directory containing variant folders
    variants:                     # Available dataset variants
        - node_level
        - global
        - combined
    default_variant: "combined"   # Default variant to use
    file_format: "h5"             # Dataset file format

# Temporal signal settings
temporal:
    window_size: 10               # Window size for temporal signals
    train_ratio: 0.8              # Train/test split ratio
    validation_ratio: 0.1         # Validation split ratio (from train)
    sequence_length: 200          # Length of each sequence
    min_sequence_length: 50       # Minimum sequence length to consider

# Feature settings
features:
    node_level:
        dimension: 6              # Number of node-level features
        types:                    # Feature types included
            - degree
            - betweenness
            - eigenvector
            - closeness
            - svd
            - lsvd
    
    global:
        dimension: 906            # 900 (adjacency) + 6 (features)
        adjacency_size: 900       # 30x30 flattened adjacency
        feature_size: 6           # Number of global features
    
    combined:
        dimension: 36             # 30 (adjacency) + 6 (features)
        adjacency_size: 30        # Per-node adjacency information
        feature_size: 6           # Number of node features

# Graph settings
graph:
    num_nodes: 30                # Number of nodes per graph
    types:                       # Available graph types
        - BA
        - ER
        - NW
    change_point:
        min_distance: 30         # Minimum distance between change points
        max_changes: 4           # Maximum number of changes per sequence

# Data processing
processing:
    normalize_features: true     # Whether to normalize features
    normalize_adjacency: false   # Whether to normalize adjacency matrices
    add_self_loops: false        # Whether to add self-loops to graphs
    undirected: true             # Whether graphs are undirected

# Training settings
training:
    batch_size: 32              # Batch size for training
    shuffle: true               # Whether to shuffle sequences
    num_workers: 4              # Number of data loading workers
    pin_memory: true            # Whether to pin memory for GPU training
    prefetch_factor: 2          # Number of batches to prefetch

# Validation settings
validation:
    frequency: 1                # Validate every N epochs
    metrics:                    # Metrics to track
        - accuracy
        - precision
        - recall
        - f1
    early_stopping:
        patience: 10            # Number of epochs to wait for improvement
        min_delta: 0.001        # Minimum change to qualify as improvement

# Testing settings
testing:
    save_predictions: true      # Whether to save model predictions
    save_features: true         # Whether to save extracted features
    metrics:                    # Additional test metrics
        - confusion_matrix
        - roc_curve
        - pr_curve

# Logging settings
logging:
    level: "INFO"             # Logging level
    save_dir: "logs"          # Directory for log files
    tensorboard: true         # Whether to use tensorboard
    wandb: false              # Whether to use weights & biases
