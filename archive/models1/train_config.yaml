# Training Configuration
paths:
  data_dir: "dataset"
  output_dir: "outputs"

# Random seed for reproducibility
seed: 42

data:
  # Sequence parameters
  window_size: 20
  stride: 5
  forecast_horizon: 10
  batch_size: 128
  
  # Feature selection
  use_centrality: true
  use_spectral: true
  enable_augmentation: false
  noise_level: 0.01
  
  # Dataset constants
  num_nodes: 100
  max_seq_length: 200
  min_seq_length: 161
  num_change_points: 2
  
  # Feature dimensions
  svd_dim: 2
  lsvd_dim: 16

model:
  # Model architecture
  hidden_dim: 512        # Changed from 256 to 512 to match LSTM expectations
  num_layers: 2          # Reduced from 3 to 2 for better stability
  dropout: 0.2
  
  # Feature processing
  use_node_features: true
  use_edge_features: true
  combine_features: "concat"
  
  # GNN parameters
  gnn_type: "gcn"
  attention_heads: 4     # Changed from 8 to 4 (must divide hidden_dim evenly: 512/4=128)
  
  # LSTM parameters
  lstm_layers: 2         # Changed from 3 to 2 to match num_layers
  bidirectional: false   # Changed to false to match decoder expectations
  
  # Training parameters
  learning_rate: 0.001
  weight_decay: 0.0001
  clip_grad_norm: 1.0

training:
  epochs: 5
  patience: 15
  val_interval: 1
  save_interval: 5
  
  # Loss function weights
  loss_weights:
    degree: 1.0
    betweenness: 1.0
    closeness: 1.0
    eigenvector: 1.0
    svd: 0.5
    lsvd: 0.5
    
  # Learning rate schedule
  lr_schedule:
    factor: 0.5
    patience: 5
    min_lr: 0.000001
    
  # Logging and monitoring
  log_interval: 50
  tensorboard: true

# Hardware optimization for RTX 4090
hardware:
  num_workers: 8
  pin_memory: true
  prefetch_factor: 4
  persistent_workers: true
  cuda_settings:
    allow_tf32: true
    benchmark: true
    memory_allocation: "optimal"
    max_split_size_mb: 512
